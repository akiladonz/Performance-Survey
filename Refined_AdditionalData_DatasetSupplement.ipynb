{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "Lines= []\n",
    "f = open(r'C:\\Users\\katuwawalaai\\Proposal_Analysis\\DisprotDissimilar_319.txt')\n",
    "for line in f:\n",
    "    data_line = line.rstrip().split('\\t')\n",
    "    Lines.append(data_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Uniprot_ID=[]\n",
    "AA_Sequence =[]\n",
    "Disorder_Annotations =[]\n",
    "Protein_Annotations =[]\n",
    "NUC_Annotations =[]\n",
    "J = len(Lines)-4\n",
    "b =0\n",
    "for b in range(0,J,5):\n",
    "    Uniprot_ID.append(Lines[b][0])\n",
    "    AA_Sequence.append(list(Lines[b+1][0]))\n",
    "    Disorder_Annotations.append(list(Lines[b+2][0]))\n",
    "    Protein_Annotations.append(list(Lines[b+3][0]))\n",
    "    NUC_Annotations.append(list(Lines[b+4][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1162"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Disorder_Annotations[318])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lines= []\n",
    "f = open(r'C:\\Users\\katuwawalaai\\Proposal_Analysis\\DisprotDissimilar_319Predictions.txt')\n",
    "for line in f:\n",
    "    data_line = line.rstrip().split('\\t')\n",
    "    Lines.append(data_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Uniprot_ID=[]\n",
    "IUPSBinary_byProteins =[]\n",
    "IUPSScore_byProteins =[]\n",
    "IUPLBinary_byProteins=[]\n",
    "IUPLScore_byProteins=[]\n",
    "EspXBinary_byProteins=[]\n",
    "EspXScore_byProteins=[]\n",
    "EspDBinary_byProteins=[]\n",
    "EspDScore_byProteins=[]\n",
    "EspNBinary_byProteins=[]\n",
    "EspNScore_byProteins=[]\n",
    "DisHLBinary_byProteins=[]\n",
    "DisHLScore_byProteins=[]\n",
    "Vsl2bBinary_byProteins=[]\n",
    "Vsl2bScore_byProteins=[]\n",
    "GlobBinary_byProteins=[]\n",
    "GlobScore_byProteins=[]\n",
    "DisopredBinary_byProteins=[]\n",
    "DisopredScore_byProteins=[]\n",
    "SpotBinary_byProteins=[]\n",
    "SpotScore_byProteins=[]\n",
    "J = len(Lines)-20\n",
    "b =0\n",
    "for b in range(0,J,21):\n",
    "    Uniprot_ID.append(Lines[b][0])\n",
    "    IUPSBinary_byProteins.append(list(Lines[b+1][0])) \n",
    "    IUPSScore_byProteins.append((Lines[b+2][0].rstrip().split(',')))  \n",
    "    IUPLBinary_byProteins.append(list(Lines[b+3][0]))  \n",
    "    IUPLScore_byProteins.append((Lines[b+4][0].rstrip().split(',')))  \n",
    "    EspXBinary_byProteins.append(list(Lines[b+5][0]))   \n",
    "    EspXScore_byProteins.append((Lines[b+6][0].rstrip().split(',')))  \n",
    "    EspDBinary_byProteins.append(list(Lines[b+7][0])) \n",
    "    EspDScore_byProteins.append((Lines[b+8][0].rstrip().split(',')))  \n",
    "    EspNBinary_byProteins.append(list(Lines[b+9][0]))  \n",
    "    EspNScore_byProteins.append((Lines[b+10][0].rstrip().split(',')))  \n",
    "    DisHLBinary_byProteins.append(list(Lines[b+11][0])) \n",
    "    DisHLScore_byProteins.append((Lines[b+12][0].rstrip().split(',')))  \n",
    "    Vsl2bBinary_byProteins.append(list(Lines[b+13][0]))  \n",
    "    Vsl2bScore_byProteins.append((Lines[b+14][0].rstrip().split(',')))  \n",
    "    GlobBinary_byProteins.append(list(Lines[b+15][0])) \n",
    "    GlobScore_byProteins.append((Lines[b+16][0].rstrip().split(',')))  \n",
    "    DisopredBinary_byProteins.append(list(Lines[b+17][0]))  \n",
    "    DisopredScore_byProteins.append((Lines[b+18][0].rstrip().split(',')))  \n",
    "    SpotBinary_byProteins.append(list(Lines[b+19][0]))   \n",
    "    SpotScore_byProteins.append((Lines[b+20][0].rstrip().split(',')))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regions=[]\n",
    "Order_Indexes=[]\n",
    "b=0\n",
    "for b in range(0,len(Disorder_Annotations),1):\n",
    "         protein=Disorder_Annotations[b]\n",
    "         sequence=AA_Sequence[b]\n",
    "         regions=[]\n",
    "         orderindex=[]\n",
    "         c=0\n",
    "         for c in range(0,len(protein),1):\n",
    "                    if protein[c]=='0':\n",
    "                                   regions.append(sequence[c])\n",
    "                                   orderindex.append(c)\n",
    "         \n",
    "         ordermargins=[]\n",
    "         d = 0\n",
    "         for d in range(0, len(orderindex)-1 , 1):\n",
    "                            if orderindex[d+1]-orderindex[d] != 1:ordermargins.append(d+1)\n",
    "                        \n",
    "         regionsmul=np.split(regions,ordermargins) \n",
    "         regionind=np.split(orderindex,ordermargins) # = indexes of ordered regions in each protein\n",
    "         Regions.append(regionsmul)\n",
    "         Order_Indexes.append(regionind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Region_Reference=[]\n",
    "Region_Points=[]\n",
    "b=0\n",
    "for b in range(0,len(Order_Indexes),1):\n",
    "           sub_prots=Order_Indexes[b]\n",
    "           c=0\n",
    "           for c in range(0,len(sub_prots),1):\n",
    "                          Region_Reference.append(str(Uniprot_ID[b])+'_R'+str(c)) # giving unique id to each region \n",
    "                          Region_Points.append([b,c])   # b,c corresponding to protein id and its region id so later we can\n",
    "                                                        # easily get the indexes for corresponding region later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the alignmnet results from individual results files generated by blastp\n",
    "Lines= []\n",
    "b=0\n",
    "for b in range(1,457,1):\n",
    "          try:\n",
    "              f = open(r'C:\\Users\\katuwawalaai\\Proposal_Analysis\\SingleRegion_Ordered\\Alignment_ResultsE1\\BalstResults_'+str(b)+'.txt')\n",
    "              for line in f:\n",
    "                  data_line = line.rstrip().split('\\t')\n",
    "                  Lines.append(data_line)\n",
    "          except:\n",
    "                  Lines.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "OrderedReg=[]\n",
    "Identity=[]\n",
    "E_Val=[]\n",
    "b=0\n",
    "for b in range(0,len(Lines),1):\n",
    "     try:\n",
    "         TM=Lines[b][0].split(',')\n",
    "         OrderedReg.append(TM[0])\n",
    "         Identity.append(float(TM[2]))\n",
    "         E_Val.append(float(TM[-2]))   \n",
    "     except:\n",
    "         a=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mapped_Regions=[]\n",
    "b=0\n",
    "for b in range(0,len(OrderedReg),1):\n",
    "    if E_Val[b]<1.0:Mapped_Regions.append(OrderedReg[b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Region_Reference.reverse()\n",
    "Region_Points.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating disorder fractions of all proteins before oreder region refinement\n",
    "Order_Count= [] \n",
    "Disorder_Fraction=[]\n",
    "Length=[]\n",
    "c=0\n",
    "for c in range(0,len(Disorder_Annotations),1):\n",
    "                 order=0\n",
    "                 disorder =0\n",
    "                 Annotation=Disorder_Annotations[c]\n",
    "                 Length.append(len(Annotation))\n",
    "                 b=0\n",
    "                 for b in range(0, len(Annotation), 1):\n",
    "                                      if Annotation[b] == '0': order = order+1\n",
    "                                      elif Annotation[b] == '1': disorder = disorder+1\n",
    "                 Order_Count.append(order)\n",
    "                 Disorder_Fraction.append(disorder/len(Annotation))\n",
    "Complete_Fractions=Disorder_Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the indexes of naturally fully disordered proteins\n",
    "OriFullDis_Proteins=[]\n",
    "b=0\n",
    "for b in range(0,len(Complete_Fractions),1):\n",
    "              if Complete_Fractions[b] ==1.0:OriFullDis_Proteins.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XbadOrder(Input_List):\n",
    "            b=0\n",
    "            for b in range(0,len(Region_Reference),1):\n",
    "                if Region_Reference[b][1:] not in Mapped_Regions: \n",
    "                                        points=Region_Points[b]\n",
    "                                        if points[0] not in OriFullDis_Proteins:\n",
    "                                                  target_list=np.asarray(Input_List[points[0]]) # getting annotation list that we gonna modify\n",
    "                                                  target_list=target_list.astype(str)#conevrt that target list to an array of string\n",
    "                                                  dele_indexes=Order_Indexes[points[0]][points[1]] # getting indexes to be X d\n",
    "                                                  insertion=np.full(len(dele_indexes),'X') # creating an array of X to insert\n",
    "                                                  insertion=insertion.astype(str) # make it a string to be on safe side \n",
    "                                                  np.put(target_list, dele_indexes,insertion) # insert X to un mapped ordered indexes in target list\n",
    "                                                  new_anno=target_list.tolist() # convert modified array back to a list \n",
    "                                                  Input_List[points[0]]=new_anno # assign modified list back to the original list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "XbadOrder(Disorder_Annotations)\n",
    "XbadOrder(Protein_Annotations)\n",
    "XbadOrder(NUC_Annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding  all non fully disordered proteins\n",
    "New_Disorder_Annotations =[]\n",
    "New_Protein_Annotations =[]\n",
    "New_NUC_Annotations =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=0\n",
    "for b in range(0,len(Disorder_Annotations),1):\n",
    "                  New_Disorder_Annotations.append( Disorder_Annotations[b])\n",
    "                  New_Protein_Annotations.append(Protein_Annotations[b])\n",
    "                  New_NUC_Annotations.append(NUC_Annotations[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(New_Disorder_Annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disorder_Annotations = New_Disorder_Annotations  \n",
    "Protein_Annotations =New_Protein_Annotations \n",
    "NUC_Annotations =New_NUC_Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting length of each protein to a list\n",
    "Length_EachProtein = []\n",
    "for b in range(0,len(Disorder_Annotations), 1):\n",
    "                   c = len(Disorder_Annotations[b])\n",
    "                   Length_EachProtein.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Annotations_Normal = np.concatenate(Disorder_Annotations) \n",
    "Protein_Normal =np.concatenate(Protein_Annotations)\n",
    "NUC_Normal =np.concatenate(NUC_Annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_List=['K7ZP88',\n",
    " 'Q3S2T9',\n",
    " 'Q939N5',\n",
    " 'A0A221ZS22',\n",
    " 'Q15782',\n",
    " 'Q7YS85',\n",
    " 'Q6TMG6',\n",
    " 'Q8B3M2',\n",
    " 'Q8G9Q2',\n",
    " 'Q3JLD6',\n",
    " 'A0A0K0MCJ4',\n",
    " 'Q93008',\n",
    " 'E2JF22',\n",
    " 'Q8TEP8',\n",
    " 'V5M2P5',\n",
    " 'Q2FUW1',\n",
    " 'Q00416',\n",
    " 'Q6GWS2',\n",
    " 'P96202',\n",
    " 'A0AEF4',\n",
    " 'Q9VG78',\n",
    " 'A0A0H2YST8',\n",
    " 'Q5J1Q6',\n",
    " 'Q84HI8',\n",
    " 'Q8IY92',\n",
    " 'I6X8D2',\n",
    " 'Q89444',\n",
    " 'A0A0H2YN38',\n",
    " 'P29400',\n",
    " 'Q8TCU6',\n",
    " 'Q70Z35',\n",
    " 'P76578',\n",
    " 'Q9GRZ3',\n",
    " 'P38198',\n",
    " 'G0SB58',\n",
    " 'A0A2D0TCJ6',\n",
    " 'Q8TEQ6',\n",
    " 'Q5ZTK4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the predictions only required\n",
    "IUPS_PDB=[]\n",
    "IUPL_PDB=[]\n",
    "EspX_PDB=[]\n",
    "EspD_PDB=[]\n",
    "EspN_PDB=[]\n",
    "DisHL_PDB=[]\n",
    "Vsl2b_PDB=[]\n",
    "Glob_PDB=[]\n",
    "\n",
    "b=0\n",
    "for b in range(0,len(ID_List),1):\n",
    "                    Lines= []\n",
    "                    f = open(r'C:\\Users\\katuwawalaai\\Proposal_Analysis\\DisorderPred_AdditionalPDB/'+ID_List[b]+'_DisorderPred.txt')\n",
    "                    for line in f:\n",
    "                        data_line = line.rstrip().split('\\t')\n",
    "                        Lines.append(data_line)\n",
    "                    Length_EachProtein.append(len(Lines)-1)\n",
    "                    \n",
    "                    c=0\n",
    "                    for c in range(1,len(Lines),1):\n",
    "                              IUPS_PDB.append(float(Lines[c][2]))\n",
    "                              IUPL_PDB.append(float(Lines[c][3]))\n",
    "                              EspX_PDB.append(float(Lines[c][4]))\n",
    "                              EspD_PDB.append(float(Lines[c][5]))\n",
    "                              EspN_PDB.append(float(Lines[c][6]))\n",
    "                              DisHL_PDB.append(float(Lines[c][7]))\n",
    "                              Vsl2b_PDB.append(float(Lines[c][8]))\n",
    "                              Glob_PDB.append(float(Lines[c][9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(Length_EachProtein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting continous sum off  proteins to an array\n",
    "d=np.cumsum(Length_EachProtein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75513"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(IUPS_PDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disopred = pd.read_csv(r\"C:\\Users\\katuwawalaai\\Proposal_Analysis\\DisorderPred_AdditionalPDB\\AdditionalPDB_DisopredResult.txt\", comment=\">\", delim_whitespace= True, names =['ResidueNo', 'AA', 'Prediction_Score', 'ProtBind_Score'], dtype={'ResidueNo':int, 'AA':str, 'Prediction_Score': np.float64, 'ProtBind_Score':np.float64}, skiprows=1, header=None)\n",
    "Disopred_PDB = Disopred.loc[:,('Prediction_Score')].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spot = pd.read_csv(r\"C:\\Users\\katuwawalaai\\Proposal_Analysis\\DisorderPred_AdditionalPDB\\AdditionalPDB_SpotResult.txt\", comment=\">\", delim_whitespace= True, names =['ResidueNo', 'AA', 'Prediction_Score', 'Label'], dtype={'ResidueNo':int, 'AA':str, 'Prediction_Score': np.float64, 'Label':str}, skiprows=1, header=None)\n",
    "Spot_PDB = Spot.loc[:,('Prediction_Score')].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Score_Binary(Score,t):\n",
    "                     Binary=[]\n",
    "                     b=0\n",
    "                     for b in range(0,len(Score),1):\n",
    "                            if Score[b]>=t:Binary.append(1)\n",
    "                            else:Binary.append(0)\n",
    "                     return Binary   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "IUPS_BinaryPDB=Score_Binary(IUPS_PDB,0.5)\n",
    "IUPL_BinaryPDB=Score_Binary(IUPL_PDB,0.5)\n",
    "EspX_BinaryPDB=Score_Binary(EspX_PDB,0.143)\n",
    "EspD_BinaryPDB=Score_Binary(EspD_PDB,0.507)\n",
    "EspN_BinaryPDB=Score_Binary(EspN_PDB,0.309)\n",
    "DisHL_BinaryPDB=Score_Binary(DisHL_PDB,0.5)\n",
    "Vsl2b_BinaryPDB=Score_Binary(Vsl2b_PDB,0.5)\n",
    "Glob_BinaryPDB=Score_Binary(Glob_PDB,0.0)\n",
    "Disopred_BinaryPDB=Score_Binary(Disopred_PDB,0.5)\n",
    "Spot_BinaryPDB=Score_Binary(Spot_PDB,0.49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_Disorder_Annotation=np.zeros((len(Spot_BinaryPDB),),dtype=int)\n",
    "PDB_Protein_Annotation=np.zeros((len(Spot_BinaryPDB),),dtype=int)\n",
    "PDB_NUC_Annotation=np.zeros((len(Spot_BinaryPDB),),dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disorder_Composite=list(Annotations_Normal)+list(PDB_Disorder_Annotation)\n",
    "Protein_Composite=list(Protein_Normal)+list(PDB_Protein_Annotation)\n",
    "NUC_Composite=list(NUC_Normal)+list(PDB_NUC_Annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disorder_Annotations=np.split(Disorder_Composite,d)\n",
    "Protein_Annotations=np.split(Protein_Composite,d)\n",
    "NUC_Annotations=np.split(NUC_Composite,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Disorder_Annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lines= []\n",
    "f = open(r'C:\\Users\\katuwawalaai\\Proposal_Analysis\\Additional_PDB.txt')\n",
    "for line in f:\n",
    "    data_line = line.rstrip().split('\\t')\n",
    "    Lines.append(data_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = len(Lines)-1\n",
    "b =0\n",
    "for b in range(0,J,2):\n",
    "    Uniprot_ID.append(Lines[b][0])\n",
    "    AA_Sequence.append(list(Lines[b+1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AA_Sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_Index=list(np.arange(0,len(Disorder_Annotations)-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Normal_Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lines=[]\n",
    "b=0\n",
    "for b in Normal_Index:\n",
    "             y = str(list(AA_Sequence[b]))\n",
    "             y = y[1:-1]\n",
    "             y = y.replace(\",\", \"\")\n",
    "             y = y.replace(\" \", \"\")\n",
    "             y = y.replace(\"'\", \"\")\n",
    "             x = str(list(Disorder_Annotations[b]))\n",
    "             x = x[1:-1]\n",
    "             x = x.replace(\",\", \"\")\n",
    "             x = x.replace(\" \", \"\")\n",
    "             x = x.replace(\"'\", \"\")\n",
    "             e = str(list(Protein_Annotations[b]))\n",
    "             e = e[1:-1]\n",
    "             e = e.replace(\",\", \"\")\n",
    "             e = e.replace(\" \", \"\")\n",
    "             e = e.replace(\"'\", \"\")\n",
    "             f = str(list(NUC_Annotations[b]))\n",
    "             f = f[1:-1]\n",
    "             f = f.replace(\",\", \"\")\n",
    "             f = f.replace(\" \", \"\")\n",
    "             f = f.replace(\"'\", \"\")\n",
    "             Lines.append(Uniprot_ID[b])\n",
    "             Lines.append(y)\n",
    "             Lines.append(x)\n",
    "             Lines.append(e)\n",
    "             Lines.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['>P10163',\n",
       " 'MLLILLSVALLALSSAESSSEDVSQEESLFLISGKPEGRRPQGGNQPQRPPPPPGKPQGPPPQGGNQSQGPPPPPGKPEGRPPQGGNQSQGPPPHPGKPERPPPQGGNQSQGPPPHPGKPESRPPQGGHQSQGPPPTPGKPEGPPPQGGNQSQGTPPPPGKPEGRPPQGGNQSQGPPPHPGKPERPPPQGGNQSHRPPPPPGKPERPPPQGGNQSQGPPPHPGKPEGPPPQEGNKSRSARSPPGKPQGPPQQEGNKPQGPPPPGKPQGPPPAGGNPQQPQAPPAGKPQGPPPPPQGGRPPRPAQGQQPPQ',\n",
       " 'XXXXXXXXXXXXXXXX111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111',\n",
       " 'XXXXXXXXXXXXXXXX000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000',\n",
       " 'XXXXXXXXXXXXXXXX000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000',\n",
       " '>P22531',\n",
       " 'MSYQQQQCKQPCQPPPVCPTPKCPEPCPPPKCPEPCPPPKCPQPCPPQQCQQKCPPVTPSPPCQPKCPPKSK',\n",
       " '11111111111111111111XXXXXXXXXXXXXXXXXXXXXXXXXXX1111111111111111111111111',\n",
       " '11111111111111111111XXXXXXXXXXXXXXXXXXXXXXXXXXX1111111111111111111111111',\n",
       " '00000000000000000000XXXXXXXXXXXXXXXXXXXXXXXXXXX0000000000000000000000000']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lines[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Cleaned_357Dataset.txt', 'w') as f:\n",
    "    for item in Lines:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
